
Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-NjhszVfJhvUBqmYd0tBpIE0gQNWA5II

# **Full Code**

### **Initial Analysis**
"""

!pip install opencv-python-headless

import os
import cv2
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt
from PIL import Image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler
from google.colab import drive

drive.mount('/content/drive')

base_dir = '/content/drive/MyDrive/Need/Up/Melanie/Dataset'

AiArt_dir = os.path.join(base_dir, 'AiArtData')
RealArt_dir = os.path.join(base_dir, 'RealArt')

print('total training Ai images:', len(os.listdir(AiArt_dir)))
print('total training Real images:', len(os.listdir(RealArt_dir)))

def display_images(image_paths):
    plt.figure(figsize=(10, 5))
    for i, img_path in enumerate(image_paths):
        img = cv2.imread(img_path)
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB
        plt.subplot(1, len(image_paths), i+1)
        plt.imshow(img)
        plt.axis('off')
    plt.show()

ai_art_files = os.listdir(AiArt_dir)[:2]
real_art_files = os.listdir(RealArt_dir)[:2]

display_images([os.path.join(AiArt_dir, fname) for fname in ai_art_files])
display_images([os.path.join(RealArt_dir, fname) for fname in real_art_files])

ai_art_count = len(os.listdir(AiArt_dir))
real_art_count = len(os.listdir(RealArt_dir))

print(f'Total training AiArt images: {ai_art_count}')
print(f'Total training RealArt images: {real_art_count}')

# Checking for imbalance
if abs(ai_art_count - real_art_count) / max(ai_art_count, real_art_count) > 0.2:
    print("Dataset is significantly imbalanced.")
else:
    print("Dataset is relatively balanced.")

# Example for analyzing image dimensions
from PIL import Image

first_ai_image = Image.open(os.path.join(AiArt_dir, ai_art_files[0]))
print(f"First AiArt image dimensions: {first_ai_image.size}")

first_real_image = Image.open(os.path.join(RealArt_dir, real_art_files[0]))
print(f"First RealArt image dimensions: {first_real_image.size}")

# Data Augmentation and Data Splitting
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.1,
    horizontal_flip=True,
    fill_mode='nearest',
    validation_split=0.25
)

# Training Data Generator
train_generator = train_datagen.flow_from_directory(
    base_dir,
    target_size=(255, 255),
    class_mode='categorical',
    batch_size=64,
    subset='training'  # Specify this is training data
)

# Validation Data Generator
validation_generator = train_datagen.flow_from_directory(
    base_dir,
    target_size=(255, 255),
    class_mode='categorical',
    batch_size=16,
    subset='validation'  # Specify this is validation data
)

"""### **CNN**"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

model = keras.Sequential([
    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(255, 255, 3)),
    keras.layers.MaxPooling2D(2, 2),
    keras.layers.Conv2D(64, (3, 3), activation='relu'),
    keras.layers.MaxPooling2D(2, 2),
    keras.layers.Conv2D(128, (3, 3), activation='relu'),
    keras.layers.MaxPooling2D(2, 2),
    keras.layers.Flatten(),
    keras.layers.Dense(512, activation='relu'),
    keras.layers.Dropout(0.5),
    keras.layers.Dense(2, activation='softmax')
])

model.summary()

model.compile(optimizer=Adam(learning_rate=0.001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

early_stopping = EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)

history = model.fit(
    train_generator,
    epochs=100,
    validation_data=validation_generator,
    callbacks=[early_stopping]
)

epochs_completed = len(history.history['loss'])
print(f"Training stopped at epoch: {epochs_completed}")

Adam_loss = history.history['loss']
Adam_acc = history.history['accuracy']

print(Adam_loss)
print(Adam_acc)

val_loss, val_accuracy = model.evaluate(validation_generator, verbose=0)
print(f"Optimizer: Adam, Validation Loss: {val_loss}, Validation Accuracy: {val_accuracy}")

loss, accuracy = model.evaluate(train_generator, verbose=0)
print(f"Optimizer: Adam, Training Loss: {loss}, Training Accuracy: {accuracy}")

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(len(acc))

plt.figure(figsize=(10, 6))
plt.plot(epochs, acc, 'r', label='Training accuracy', marker = 'o', linestyle = 'dashed')
plt.plot(epochs, val_acc, 'b', label='Validation accuracy', marker = 'o', linestyle = 'dashed')
plt.title('Training and validation accuracy (Epoch Based - Adam)')
plt.legend(loc=0)

plt.show()

plt.figure(figsize=(10, 6))
plt.plot(epochs, loss, 'r', label='Training loss', marker = 'o', linestyle = 'dashed')
plt.plot(epochs, val_loss, 'b', label='Validation loss', marker = 'o', linestyle = 'dashed')
plt.title('Training and validation loss (Epoch Based - Adam)')
plt.legend(loc=0)

plt.show()
